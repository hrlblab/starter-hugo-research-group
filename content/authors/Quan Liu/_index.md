---
# Display name
title: 2024-05 Quan Liu

# Is this the primary user of the site?
superuser: false

# Role/position
role: First position - Advanced AI/ML Scientist @ Accenture 

# Organizations/Affiliations
organizations:
- name: Personal Website
  url: "https://www.linkedin.com/in/quan-liu-426762172"

# Short bio (displayed in user profile at end of posts)
bio: Dr. Quan Liu defended his PhD degree in Computer Science on May 8, 2024, with title "Efficient Representation Learning for Optical Image Analysis" 

interests:
- Medical Image Analysis
- Artificial Intelligence
- Deep Learning

education:
  courses:
  - course: PhD in Computer Science
    institution: Vanderbilt University
    year: 2024
  - course: MS in Computer Engineering
    institution: Case Western Reserve University
    year: 2020
  - course: BS in Electrical Engineering
    institution: Huazhong Univeristy of Science and Technology
    year: 2018

# Enter email to display Gravatar (if Gravatar enabled in Config)
email: "quan.liu@vanderbilt.edu"

# Highlight the author in author lists? (true/false)
highlight_name: false

# Organizational groups that you belong to (for People widget)
#   Set this to `[]` or comment out if you are not using People widget.
user_groups:
- PhD Alumni
---

This thesis addresses the challenges of efficient representation learning across three crucial categories of optical images: microscopic, pathology, and meta-optic images.  Microscopic images, characterized by dense dynamic objects, often suffer from resource-intensive object annotations. To tackle this, we introduce a novel deep learning-based unsupervised sub-cellular microvilli segmentation method and propose an annotation-free video analysis paradigm. In the realm of medical optical images, we propose the SimTriplet approach, integrating GPU memory-efficient techniques with self-supervised learning to enhance computational efficiency and feature extraction. Moreover, we tackle the escalating computational demands by introducing a large convolution kernel design for LMNN models, reducing computational latency and energy consumption. We validate our approach through physical meta-material fabrication.
